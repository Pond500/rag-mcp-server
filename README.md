# ğŸš€ Multi-Knowledge Base RAG System
## Simple but Powerful - AI-Powered Document Management & Semantic Search

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Key Features](#-key-features)
- [Architecture](#-architecture)
- [Visual Workflows](#-visual-workflows)
- [Workflow 1: Document Upload Process](#-workflow-1-document-upload-process-ai-first-ingestion)
- [Workflow 2: Chat with Specific KB](#-workflow-2-chat-with-specific-kb-chat_with_kb)
- [Workflow 3: Smart Chat with Auto-Routing](#-workflow-3-smart-chat-with-auto-routing-chat_global)
- [Workflow 4: System Architecture Data Flow](#-workflow-4-system-architecture-data-flow)
- [Quick Start](#-quick-start)
- [User Journey](#-user-journey)
- [1. à¹€à¸à¸´à¹ˆà¸¡à¹€à¸­à¸à¸ªà¸²à¸£ (Upload Documents)](#1-à¹€à¸à¸´à¹ˆà¸¡à¹€à¸­à¸à¸ªà¸²à¸£-upload-documents)
- [2. à¸„à¸¸à¸¢à¸à¸±à¸šà¹€à¸­à¸à¸ªà¸²à¸£ (Chat with Documents)](#2-à¸„à¸¸à¸¢à¸à¸±à¸šà¹€à¸­à¸à¸ªà¸²à¸£-chat-with-documents)
- [MCP Tools Reference](#-mcp-tools-reference)
- [Advanced Features](#-advanced-features)
- [API Examples](#-api-examples)
- [Troubleshooting](#-troubleshooting)

---

## ğŸ¯ Overview

**Multi-KB RAG** à¹€à¸›à¹‡à¸™à¸£à¸°à¸šà¸š Retrieval-Augmented Generation (RAG) à¸—à¸µà¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š **à¸«à¸¥à¸²à¸¢ Knowledge Bases** à¹à¸¢à¸à¸à¸±à¸™à¹„à¸”à¹‰ à¸à¸£à¹‰à¸­à¸¡à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œ AI à¸—à¸µà¹ˆà¸Šà¹ˆà¸§à¸¢:

- ğŸ¤– **à¸ªà¸à¸±à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´** - AI à¸­à¹ˆà¸²à¸™à¹€à¸­à¸à¸ªà¸²à¸£à¹à¸¥à¸°à¸ªà¸£à¹‰à¸²à¸‡ metadata (à¸›à¸£à¸°à¹€à¸ à¸—, à¸«à¸¡à¸§à¸”à¸«à¸¡à¸¹à¹ˆ, à¸Šà¸·à¹ˆà¸­)
- ğŸŒ **Semantic Router** - à¸–à¸²à¸¡à¸„à¸³à¸–à¸²à¸¡à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸£à¸°à¸šà¸¸ KB â†’ à¸£à¸°à¸šà¸šà¸«à¸² KB à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¹ƒà¸«à¹‰à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
- ğŸ’¬ **Conversation Memory** - à¸ˆà¸³à¸šà¸—à¸ªà¸™à¸—à¸™à¸²à¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸² (per session)
- ğŸ“¦ **Auto-Create** - à¸­à¸±à¸à¹‚à¸«à¸¥à¸”à¹€à¸­à¸à¸ªà¸²à¸£à¸„à¸£à¸±à¹‰à¸‡à¹à¸£à¸ â†’ à¸ªà¸£à¹‰à¸²à¸‡ KB à¹ƒà¸«à¹‰à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
- ğŸ” **Vector Search** - à¸„à¹‰à¸™à¸«à¸²à¸”à¹‰à¸§à¸¢ semantic similarity (Qdrant + HuggingFace embeddings)

---

## âœ¨ Key Features

### ğŸ¨ **For Users:**
- âœ… à¸­à¸±à¸à¹‚à¸«à¸¥à¸”à¹€à¸­à¸à¸ªà¸²à¸£ PDF, TXT, DOCX à¹„à¸”à¹‰à¸—à¸±à¸™à¸—à¸µ
- âœ… à¸–à¸²à¸¡à¸„à¸³à¸–à¸²à¸¡à¸ à¸²à¸©à¸²à¹„à¸—à¸¢/à¸­à¸±à¸‡à¸à¸¤à¸© à¹„à¸”à¹‰à¸„à¸³à¸•à¸­à¸šà¸à¸£à¹‰à¸­à¸¡à¹à¸«à¸¥à¹ˆà¸‡à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡
- âœ… à¸ˆà¸±à¸”à¸£à¸°à¹€à¸šà¸µà¸¢à¸šà¹€à¸­à¸à¸ªà¸²à¸£à¹à¸¢à¸à¸•à¸²à¸¡ KB (à¹€à¸Šà¹ˆà¸™ à¹à¸¢à¸à¸•à¸²à¸¡à¸¥à¸¹à¸à¸„à¹‰à¸², à¹‚à¸›à¸£à¹€à¸ˆà¸„, à¸«à¸¡à¸§à¸”à¸«à¸¡à¸¹à¹ˆ)
- âœ… à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸ˆà¸³à¸Šà¸·à¹ˆà¸­ KB - à¹ƒà¸Šà¹‰ `chat_global` à¸£à¸°à¸šà¸šà¸«à¸²à¹ƒà¸«à¹‰

### ğŸ› ï¸ **For Developers:**
- âœ… **8 MCP Tools** - Integration-ready à¸ªà¸³à¸«à¸£à¸±à¸š AI Agents (Dify, etc.)
- âœ… **RESTful API** - FastAPI + JSON-RPC protocol
- âœ… **Scalable** - à¸£à¸­à¸‡à¸£à¸±à¸š 1000+ KBs, millions of documents
- âœ… **Logging & Monitoring** - Rotating logs + Prometheus metrics ready
- âœ… **Docker Support** - Qdrant vector database

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      User / AI Agent                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MCP Server (FastAPI + JSON-RPC)                â”‚
â”‚  8 Tools: create, upload, chat, chat_global, list, etc.     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Multi-KB RAG Engine (Python)                   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ AI Metadata  â”‚  â”‚   Semantic   â”‚  â”‚ Conversation â”‚       â”‚
â”‚  â”‚  Extraction  â”‚  â”‚    Router    â”‚  â”‚    Memory    â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Qdrant     â”‚  â”‚ HuggingFace  â”‚  â”‚   OpenAI     â”‚
â”‚ Vector Store  â”‚  â”‚  bge-m3 (1k) â”‚  â”‚ Compatible   â”‚
â”‚   (Docker)    â”‚  â”‚  Embeddings  â”‚  â”‚     LLM      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Data Flow:**

```
1. User uploads PDF
   â†“
2. AI extracts metadata (doc_type, category, title)
   â†“
3. Generate smart description: "[Legal] Gun License Guide - Category: Legal"
   â†“
4. Create KB collection (if not exists)
   â†“
5. Split document into chunks
   â†“
6. Generate embeddings (1024-dim vectors)
   â†“
7. Store in Qdrant + Update Master Router Index
   â†“
8. User can chat with KB or use chat_global (auto-route)
```

---

## ï¿½ Visual Workflows

### **ğŸ”„ Workflow 1: Document Upload Process (AI-First Ingestion)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DOCUMENT UPLOAD WORKFLOW                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    User/Agent                MCP Server           Multi-KB Engine           Qdrant/LLM
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚  1. upload_document      â”‚                      â”‚                      â”‚
        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                      â”‚                      â”‚
        â”‚  (kb_name, file_content) â”‚                      â”‚                      â”‚
        â”‚                          â”‚  2. Extract Text     â”‚                      â”‚
        â”‚                          â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                      â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  3. Extract first    â”‚                      â”‚
        â”‚                          â”‚     page content     â”‚                      â”‚
        â”‚                          â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  4. AI Metadata      â”‚  5. LLM API Call     â”‚
        â”‚                          â”‚     Extraction       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
        â”‚                          â”‚                      â”‚ (extract doc_type,   â”‚
        â”‚                          â”‚                      â”‚  title, category)    â”‚
        â”‚                          â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  6. Generate Smart   â”‚                      â”‚
        â”‚                          â”‚     Description      â”‚                      â”‚
        â”‚                          â”‚  "[type] title -     â”‚                      â”‚
        â”‚                          â”‚   Category: cat"     â”‚                      â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  7. Create/Check     â”‚  8. Create Collectionâ”‚
        â”‚                          â”‚     Collection       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
        â”‚                          â”‚  (if auto_create)    â”‚  (kb_{kb_name})      â”‚
        â”‚                          â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  9. Chunk Document   â”‚                      â”‚
        â”‚                          â”‚  (split into pages   â”‚                      â”‚
        â”‚                          â”‚   + paragraphs)      â”‚                      â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  10. Generate        â”‚  11. Embed Chunks    â”‚
        â”‚                          â”‚      Embeddings      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
        â”‚                          â”‚                      â”‚  (bge-m3, 1024-dim)  â”‚
        â”‚                          â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  12. Store Vectors   â”‚  13. Upsert Points   â”‚
        â”‚                          â”‚      + Metadata      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
        â”‚                          â”‚                      â”‚  (vectors + payload) â”‚
        â”‚                          â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  14. Update Router   â”‚  15. Embed Descriptionâ”‚
        â”‚                          â”‚      Index           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
        â”‚                          â”‚  (master_router_     â”‚  (for semantic       â”‚
        â”‚                          â”‚   index)             â”‚   routing)           â”‚
        â”‚                          â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  16. Store in Router â”‚  17. Upsert to       â”‚
        â”‚                          â”‚                      â”‚      Router Index    â”‚
        â”‚                          â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
        â”‚                          â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  18. Return Success  â”‚                      â”‚
        â”‚                          â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚
        â”‚  19. Success Response    â”‚                      â”‚                      â”‚
        â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚                      â”‚
        â”‚  {success: true,         â”‚                      â”‚                      â”‚
        â”‚   kb_name, description,  â”‚                      â”‚                      â”‚
        â”‚   metadata, chunks}      â”‚                      â”‚                      â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â–¼                          â–¼                      â–¼                      â–¼

ğŸ“Š Result:
  âœ… Document stored in Qdrant collection: kb_{kb_name}
  âœ… AI-extracted metadata attached to all chunks
  âœ… Master router index updated with KB description
  âœ… Ready for semantic search and chat queries
```

---

### **ğŸ’¬ Workflow 2: Chat with Specific KB (chat_with_kb)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       CHAT WITH KNOWLEDGE BASE                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    User/Agent                MCP Server           Multi-KB Engine           Qdrant/LLM
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚  1. chat_with_kb         â”‚                      â”‚                      â”‚
        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                      â”‚                      â”‚
        â”‚  (kb_name, query,        â”‚                      â”‚                      â”‚
        â”‚   session_id, top_k)     â”‚                      â”‚                      â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  2. Load Chat        â”‚                      â”‚
        â”‚                          â”‚     History          â”‚                      â”‚
        â”‚                          â”‚  (from memory)       â”‚                      â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  3. Embed Query      â”‚  4. Generate Vector  â”‚
        â”‚                          â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
        â”‚                          â”‚                      â”‚  (bge-m3, 1024-dim)  â”‚
        â”‚                          â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  5. Vector Search    â”‚  6. Cosine Similarityâ”‚
        â”‚                          â”‚     (top_k results)  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
        â”‚                          â”‚                      â”‚  Search in kb_{name} â”‚
        â”‚                          â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
        â”‚                          â”‚                      â”‚  [doc1, doc2, ...]   â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  7. Build Context    â”‚                      â”‚
        â”‚                          â”‚  (retrieved docs +   â”‚                      â”‚
        â”‚                          â”‚   chat history)      â”‚                      â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  8. Generate Answer  â”‚  9. LLM API Call     â”‚
        â”‚                          â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
        â”‚                          â”‚                      â”‚  (context + query)   â”‚
        â”‚                          â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
        â”‚                          â”‚                      â”‚  AI-generated answer â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  10. Save to History â”‚                      â”‚
        â”‚                          â”‚   (query + answer)   â”‚                      â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  11. Format Response â”‚                      â”‚
        â”‚                          â”‚   (answer + sources) â”‚                      â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  12. Return Result   â”‚                      â”‚
        â”‚                          â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚
        â”‚  13. Chat Response       â”‚                      â”‚                      â”‚
        â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚                      â”‚
        â”‚  {answer: "...",         â”‚                      â”‚                      â”‚
        â”‚   sources: [...],        â”‚                      â”‚                      â”‚
        â”‚   kb_name: "..."}        â”‚                      â”‚                      â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â–¼                          â–¼                      â–¼                      â–¼

ğŸ“Š Result:
  âœ… AI-generated answer based on retrieved documents
  âœ… Source citations with page numbers and similarity scores
  âœ… Conversation history saved for context continuity
```

---

### **ğŸ¯ Workflow 3: Smart Chat with Auto-Routing (chat_global)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SEMANTIC ROUTER AUTO-ROUTING CHAT                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    User/Agent                MCP Server           Multi-KB Engine           Qdrant/LLM
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚  1. chat_global          â”‚                      â”‚                      â”‚
        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                      â”‚                      â”‚
        â”‚  (query, session_id,     â”‚                      â”‚                      â”‚
        â”‚   top_k)                 â”‚                      â”‚                      â”‚
        â”‚  âš¡ NO kb_name specified! â”‚                      â”‚                      â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  2. Embed Query      â”‚  3. Generate Vector  â”‚
        â”‚                          â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
        â”‚                          â”‚                      â”‚  (bge-m3, 1024-dim)  â”‚
        â”‚                          â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  4. Search Router    â”‚  5. Query Master     â”‚
        â”‚                          â”‚     Index            â”‚     Router Index     â”‚
        â”‚                          â”‚  (find best KB)      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
        â”‚                          â”‚                      â”‚  (master_router_     â”‚
        â”‚                          â”‚                      â”‚   index collection)  â”‚
        â”‚                          â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
        â”‚                          â”‚                      â”‚  [{kb: "gun_law",    â”‚
        â”‚                          â”‚                      â”‚    score: 0.87}]     â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  6. Check Threshold  â”‚                      â”‚
        â”‚                          â”‚  (score >= 0.4?)     â”‚                      â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚                      â”‚
        â”‚        â–¼ YES                         â–¼ NO       â”‚                      â”‚
        â”‚   Found Match!                  No Match        â”‚                      â”‚
        â”‚   kb_name = "gun_law"          Return Error     â”‚                      â”‚
        â”‚   confidence = 0.87            (below threshold)â”‚                      â”‚
        â”‚        â”‚                              â”‚         â”‚                      â”‚
        â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚                      â”‚
        â”‚                       â–¼                         â”‚                      â”‚
        â”‚                          â”‚  7. Route to KB      â”‚                      â”‚
        â”‚                          â”‚  (call chat_with_kb  â”‚                      â”‚
        â”‚                          â”‚   with found kb_name)â”‚                      â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  8-13. Same as       â”‚  [Vector Search +    â”‚
        â”‚                          â”‚   "Chat with KB"     â”‚   LLM Generation]    â”‚
        â”‚                          â”‚   workflow           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
        â”‚                          â”‚   (see Workflow 2)   â”‚               â”‚      â”‚
        â”‚                          â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â”‚                          â”‚  14. Return Result + â”‚                      â”‚
        â”‚                          â”‚      Routing Info    â”‚                      â”‚
        â”‚                          â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚
        â”‚  15. Chat Response       â”‚                      â”‚                      â”‚
        â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚                      â”‚
        â”‚  {answer: "...",         â”‚                      â”‚                      â”‚
        â”‚   sources: [...],        â”‚                      â”‚                      â”‚
        â”‚   kb_name: "gun_law",    â”‚                      â”‚                      â”‚
        â”‚   confidence: 0.87}      â”‚ âš¡ Extra metadata!    â”‚                      â”‚
        â”‚                          â”‚                      â”‚                      â”‚
        â–¼                          â–¼                      â–¼                      â–¼

ğŸ“Š Result:
  âœ… AI automatically found the most relevant KB
  âœ… User doesn't need to know KB names
  âœ… Routing confidence score provided for transparency
  âœ… Seamless experience like chatting with entire knowledge base
```

---

### **ğŸ—ï¸ Workflow 4: System Architecture Data Flow**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     COMPLETE SYSTEM DATA FLOW                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚                     â”‚
                              â”‚  User / AI Agent    â”‚
                              â”‚  (Dify, Claude,     â”‚
                              â”‚   ChatGPT, etc.)    â”‚
                              â”‚                     â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â”‚ HTTP POST /mcp
                                         â”‚ (JSON-RPC 2.0)
                                         â”‚
                                         â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    MCP Server (FastAPI)                â”‚
                    â”‚                                        â”‚
                    â”‚  ğŸ› ï¸  8 Available Tools:                â”‚
                    â”‚  1. create_collection                  â”‚
                    â”‚  2. upload_document_to_kb              â”‚
                    â”‚  3. chat_with_kb                       â”‚
                    â”‚  4. chat_global        â­ NEW          â”‚
                    â”‚  5. list_collections                   â”‚
                    â”‚  6. get_collection_info                â”‚
                    â”‚  7. clear_chat_history                 â”‚
                    â”‚  8. delete_collection                  â”‚
                    â”‚                                        â”‚
                    â”‚  ğŸ“Š Request Middleware:                â”‚
                    â”‚  - Logs all requests                   â”‚
                    â”‚  - Timing metrics                      â”‚
                    â”‚  - Error tracking                      â”‚
                    â”‚                                        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â”‚ Python function calls
                                   â”‚
                                   â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚          Multi-KB RAG Engine (Core Logic)                â”‚
        â”‚                                                          â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚  â”‚  AI Metadata   â”‚  â”‚    Semantic    â”‚  â”‚   Chat    â”‚   â”‚
        â”‚  â”‚   Extractor    â”‚  â”‚     Router     â”‚  â”‚  History  â”‚   â”‚
        â”‚  â”‚                â”‚  â”‚                â”‚  â”‚  Manager  â”‚   â”‚
        â”‚  â”‚ â€¢ Extract type â”‚  â”‚ â€¢ Master Index â”‚  â”‚ â€¢ Per-    â”‚   â”‚
        â”‚  â”‚ â€¢ Extract cat  â”‚  â”‚ â€¢ Route to KB  â”‚  â”‚   session â”‚   â”‚
        â”‚  â”‚ â€¢ Extract titleâ”‚  â”‚ â€¢ Threshold    â”‚  â”‚ â€¢ Context â”‚   â”‚
        â”‚  â”‚ â€¢ Generate descâ”‚  â”‚   0.4+         â”‚  â”‚   aware   â”‚   â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â”‚                                                          â”‚
        â”‚  ğŸ“ Document Processing:                                 â”‚
        â”‚  - Text extraction (PDF/DOCX/TXT)                        â”‚
        â”‚  - Chunking (configurable size)                          â”‚
        â”‚  - Metadata enrichment                                   â”‚
        â”‚                                                         â”‚
        â”‚  ğŸ” Search Pipeline:                                    â”‚
        â”‚  - Query embedding                                      â”‚
        â”‚  - Vector similarity search                             â”‚
        â”‚  - Context ranking                                      â”‚
        â”‚  - Answer generation                                    â”‚
        â”‚                                                         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                 â”‚                  â”‚
                 â”‚                 â”‚                  â”‚
                 â–¼                 â–¼                  â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚     Qdrant        â”‚  â”‚ HuggingFace  â”‚  â”‚   OpenAI-       â”‚
     â”‚  Vector Database  â”‚  â”‚   Embeddings â”‚  â”‚  Compatible     â”‚
     â”‚                   â”‚  â”‚              â”‚  â”‚      LLM        â”‚
     â”‚  Collections:     â”‚  â”‚  Model:      â”‚  â”‚                 â”‚
     â”‚  â€¢ kb_{name}      â”‚  â”‚  bge-m3      â”‚  â”‚  Tasks:         â”‚
     â”‚  â€¢ kb_{name}_2    â”‚  â”‚              â”‚  â”‚  â€¢ Generate     â”‚
     â”‚  â€¢ master_router_ â”‚  â”‚  Dimension:  â”‚  â”‚    answers      â”‚
     â”‚    index  â­      â”‚  â”‚  1024        â”‚  â”‚  â€¢ Extract      â”‚
     â”‚                   â”‚  â”‚              â”‚  â”‚    metadata     â”‚
     â”‚  Features:        â”‚  â”‚  Language:   â”‚  â”‚  â€¢ Summarize    â”‚
     â”‚  â€¢ HNSW index     â”‚  â”‚  Multi-      â”‚  â”‚                 â”‚
     â”‚  â€¢ Cosine sim     â”‚  â”‚  lingual     â”‚  â”‚  API:           â”‚
     â”‚  â€¢ Metadata       â”‚  â”‚  (Thai/Eng)  â”‚  â”‚  OpenAI-        â”‚
     â”‚    filtering      â”‚  â”‚              â”‚  â”‚  compatible     â”‚
     â”‚  â€¢ Scalable       â”‚  â”‚              â”‚  â”‚                 â”‚
     â”‚                   â”‚  â”‚              â”‚  â”‚                 â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â–²                     â–²                   â–²
              â”‚                     â”‚                   â”‚
              â”‚                     â”‚                   â”‚
        Docker Volume          HTTP API            HTTP API
        (persistent)         (embedding)         (completion)


ğŸ“Š Key Data Structures:

1. Document Chunk (stored in Qdrant):
   {
     "text": "à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•...",
     "metadata": {
       "filename": "gun_license_handbook.pdf",
       "page_number": 5,
       "doc_type": "Official Document",
       "category": "Legal",
       "kb_name": "gun_law"
     },
     "vector": [0.123, -0.456, ..., 0.789]  // 1024 dimensions
   }

2. Router Index Entry (master_router_index):
   {
     "kb_name": "gun_law",
     "description": "[Official Document] à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™ - Category: Legal",
     "vector": [0.321, 0.654, ..., -0.987]  // 1024 dimensions
   }

3. Chat History (in-memory):
   {
     "session_id": "user123_gun_20251125",
     "messages": [
       {"role": "user", "content": "à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•..."},
       {"role": "assistant", "content": "à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸¡à¸µ 5 à¸‚à¸±à¹‰à¸™..."}
     ]
   }
```

---

## ï¿½ğŸš€ Quick Start

### **Prerequisites:**

- Python 3.10+
- Docker (for Qdrant)
- OpenAI-compatible LLM endpoint

### **Installation:**

```bash
# 1. Clone repository
git clone https://github.com/YourRepo/rag-mcp-server.git
cd rag-mcp-server

# 2. Create virtual environment
python3 -m venv venv_clean
source venv_clean/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Start Qdrant (vector database)
docker-compose up -d qdrant

# 5. Configure environment
cp .env.example .env
# Edit .env with your LLM API key

# 6. Start server
./start_multi_kb.sh
```

Server à¸ˆà¸°à¸£à¸±à¸™à¸—à¸µà¹ˆ: `http://localhost:8000`

---

## ğŸ‘¤ User Journey

## 1. à¹€à¸à¸´à¹ˆà¸¡à¹€à¸­à¸à¸ªà¸²à¸£ (Upload Documents)

### **à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆ 1: à¸œà¹ˆà¸²à¸™ Dify Agent (à¹à¸™à¸°à¸™à¸³)**

**Scenario:** à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸­à¸±à¸à¹‚à¸«à¸¥à¸”à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™

#### **Step 1: à¹€à¸•à¸£à¸µà¸¢à¸¡à¹€à¸­à¸à¸ªà¸²à¸£**
```
à¹„à¸Ÿà¸¥à¹Œ: gun_license_handbook.pdf
à¸‚à¸™à¸²à¸”: 5.2 MB
à¸ à¸²à¸©à¸²: à¹„à¸—à¸¢
à¸«à¸™à¹‰à¸²: 45 à¸«à¸™à¹‰à¸²
```

#### **Step 2: à¸šà¸­à¸ Agent**
```
User: "à¸­à¸±à¸à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸„à¸¹à¹ˆà¸¡à¸·à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™à¸™à¸µà¹‰à¹ƒà¸«à¹‰à¸«à¸™à¹ˆà¸­à¸¢ [à¹à¸™à¸šà¹„à¸Ÿà¸¥à¹Œ gun_license_handbook.pdf]"
```

#### **Step 3: Agent à¸—à¸³à¸‡à¸²à¸™à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´**

**Agent à¸ˆà¸°à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰ tool: `upload_document_to_kb`**

```json
{
  "kb_name": "gun_law",
  "file_content": "JVBERi0xLjQKJeLjz9MKMSAwIG9iago8PAovVH...",
  "filename": "gun_license_handbook.pdf",
  "content_type": "application/pdf",
  "auto_create": true
}
```

#### **Step 4: à¸£à¸°à¸šà¸šà¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥ (Behind the scenes)**

```
ğŸ“„ Extracting text from gun_license_handbook.pdf...
   âœ“ Extracted 45 pages

ğŸ¤– AI Extracting metadata from document...
   âœ“ AI Metadata extracted: {
       "doc_type": "Official Document",
       "category": "Legal",
       "status": "Published",
       "title": "à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™ (à¸.à¸£.à¸š. à¸­à¸²à¸§à¸¸à¸˜à¸›à¸·à¸™)"
     }

ğŸ“ Generated description: 
   "[Official Document] à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™ - Category: Legal"

ğŸ“¦ Collection 'gun_law' not found, creating with AI-generated description...
   âœ“ Collection created: kb_gun_law
   Description: [Official Document] à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™ - Category: Legal

ğŸ“ Creating documents from 45 pages...
   âœ“ Created 892 chunks

âœ… Successfully uploaded gun_license_handbook.pdf to gun_law
   KB Name: gun_law
   Collection: kb_gun_law
   Description: [Official Document] à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™ - Category: Legal
   AI Metadata: {doc_type: "Official Document", category: "Legal", ...}

âœ… Updated router index for: gun_law
```

#### **Step 5: Agent à¸•à¸­à¸šà¸à¸¥à¸±à¸š**
```
Agent: "âœ… à¸­à¸±à¸à¹‚à¸«à¸¥à¸”à¹€à¸­à¸à¸ªà¸²à¸£à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§à¸„à¹ˆà¸°!

ğŸ“š Knowledge Base: gun_law
ğŸ“„ à¹„à¸Ÿà¸¥à¹Œ: gun_license_handbook.pdf (45 à¸«à¸™à¹‰à¸²)
ğŸ¤– AI à¸•à¸£à¸§à¸ˆà¸à¸šà¸§à¹ˆà¸²à¹€à¸›à¹‡à¸™: Official Document (Legal)
ğŸ“ à¸Šà¸·à¹ˆà¸­à¹€à¸­à¸à¸ªà¸²à¸£: à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™

à¸£à¸°à¸šà¸šà¹„à¸”à¹‰à¹à¸šà¹ˆà¸‡à¹€à¸­à¸à¸ªà¸²à¸£à¹€à¸›à¹‡à¸™ 892 à¸ªà¹ˆà¸§à¸™ à¹à¸¥à¸°à¸ˆà¸±à¸”à¹€à¸à¹‡à¸šà¹„à¸§à¹‰à¹à¸¥à¹‰à¸§
à¸à¸£à¹‰à¸­à¸¡à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¹ƒà¸™à¹€à¸­à¸à¸ªà¸²à¸£à¹„à¸”à¹‰à¹€à¸¥à¸¢à¸„à¹ˆà¸°!"
```

---

### **à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆ 2: à¸œà¹ˆà¸²à¸™ API à¹‚à¸”à¸¢à¸•à¸£à¸‡**

```bash
# à¹à¸›à¸¥à¸‡à¹„à¸Ÿà¸¥à¹Œà¹€à¸›à¹‡à¸™ base64
base64 -i gun_license_handbook.pdf -o file.b64

# à¹€à¸£à¸µà¸¢à¸ API
curl -X POST http://localhost:8000/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "id": 1,
    "method": "tools/call",
    "params": {
      "name": "upload_document_to_kb",
      "arguments": {
        "kb_name": "gun_law",
        "file_content": "'$(cat file.b64)'",
        "filename": "gun_license_handbook.pdf",
        "content_type": "application/pdf",
        "auto_create": true
      }
    }
  }'
```

---

### **ğŸ¨ à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¹€à¸à¸´à¸”à¸‚à¸¶à¹‰à¸™à¸ à¸²à¸¢à¹ƒà¸™:**

1. **AI à¸­à¹ˆà¸²à¸™à¹€à¸­à¸à¸ªà¸²à¸£ (à¸«à¸™à¹‰à¸²à¹à¸£à¸):**
   - à¹ƒà¸Šà¹‰ LLM à¸ªà¸à¸±à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥: à¸›à¸£à¸°à¹€à¸ à¸—à¹€à¸­à¸à¸ªà¸²à¸£, à¸«à¸¡à¸§à¸”à¸«à¸¡à¸¹à¹ˆ, à¸Šà¸·à¹ˆà¸­, à¸ªà¸–à¸²à¸™à¸°
   - à¸ªà¸£à¹‰à¸²à¸‡ description à¸—à¸µà¹ˆà¸­à¸˜à¸´à¸šà¸²à¸¢à¹€à¸™à¸·à¹‰à¸­à¸«à¸²

2. **à¸ªà¸£à¹‰à¸²à¸‡ Knowledge Base:**
   - à¸–à¹‰à¸² KB à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µ â†’ à¸ªà¸£à¹‰à¸²à¸‡à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´ (auto_create=true)
   - à¸•à¸±à¹‰à¸‡à¸Šà¸·à¹ˆà¸­: `kb_gun_law` (normalize: lowercase + underscore)

3. **à¹à¸šà¹ˆà¸‡à¹€à¸­à¸à¸ªà¸²à¸£ (Chunking):**
   - Split à¹€à¸›à¹‡à¸™ chunks (à¸‚à¸™à¸²à¸” configurable)
   - à¹à¸•à¹ˆà¸¥à¸° chunk à¸¡à¸µ metadata: filename, page_number, doc_type, category

4. **à¸ªà¸£à¹‰à¸²à¸‡ Embeddings:**
   - à¹ƒà¸Šà¹‰ HuggingFace bge-m3 model
   - à¹à¸›à¸¥à¸‡ text â†’ 1024-dim vectors

5. **à¹€à¸à¹‡à¸šà¹ƒà¸™ Qdrant:**
   - Upload vectors + metadata
   - Index à¸”à¹‰à¸§à¸¢ HNSW algorithm (fast cosine similarity search)

6. **Update Semantic Router:**
   - Embed description â†’ à¹€à¸à¹‡à¸šà¹ƒà¸™ `master_router_index`
   - à¹ƒà¸Šà¹‰à¸ªà¸³à¸«à¸£à¸±à¸š auto-routing à¸ à¸²à¸¢à¸«à¸¥à¸±à¸‡

---

## 2. à¸„à¸¸à¸¢à¸à¸±à¸šà¹€à¸­à¸à¸ªà¸²à¸£ (Chat with Documents)

### **à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆ 1: à¸£à¸°à¸šà¸¸ KB à¸Šà¸±à¸”à¹€à¸ˆà¸™ (chat_with_kb)**

**Scenario:** à¸£à¸¹à¹‰à¸§à¹ˆà¸²à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸–à¸²à¸¡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸š gun_law KB

#### **Step 1: à¸–à¸²à¸¡à¸„à¸³à¸–à¸²à¸¡**
```
User: "à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™à¸¡à¸µà¸­à¸°à¹„à¸£à¸šà¹‰à¸²à¸‡?"
```

#### **Step 2: Agent à¹€à¸¥à¸·à¸­à¸ Tool**

**Agent à¸£à¸¹à¹‰à¸§à¹ˆà¸²à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ KB = gun_law â†’ à¹€à¸£à¸µà¸¢à¸ `chat_with_kb`**

```json
{
  "kb_name": "gun_law",
  "query": "à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™à¸¡à¸µà¸­à¸°à¹„à¸£à¸šà¹‰à¸²à¸‡?",
  "session_id": "user123_gun_20251125",
  "top_k": 5
}
```

#### **Step 3: à¸£à¸°à¸šà¸šà¸„à¹‰à¸™à¸«à¸² (Behind the scenes)**

```
1ï¸âƒ£ Embed query â†’ [0.23, -0.45, 0.89, ...] (1024-dim)

2ï¸âƒ£ Search kb_gun_law collection
   - Cosine similarity with all vectors
   - Top-5 most similar chunks:
   
   Chunk 1 (score: 0.92):
   "à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸¢à¸·à¹ˆà¸™à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™
    1. à¹€à¸•à¸£à¸µà¸¢à¸¡à¹€à¸­à¸à¸ªà¸²à¸£à¸›à¸£à¸°à¸à¸­à¸š...
    2. à¸¢à¸·à¹ˆà¸™à¸„à¸³à¸‚à¸­à¸—à¸µà¹ˆà¸ªà¸–à¸²à¸™à¸µà¸•à¸³à¸£à¸§à¸ˆ..."
   
   Chunk 2 (score: 0.88):
   "à¹€à¸­à¸à¸ªà¸²à¸£à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•
    - à¸ªà¸³à¹€à¸™à¸²à¸šà¸±à¸•à¸£à¸›à¸£à¸°à¸Šà¸²à¸Šà¸™
    - à¸ªà¸³à¹€à¸™à¸²à¸—à¸°à¹€à¸šà¸µà¸¢à¸™à¸šà¹‰à¸²à¸™..."
   
   [3 more chunks...]

3ï¸âƒ£ Retrieve conversation history (session: user123_gun_20251125)
   - Previous Q&A (if any)

4ï¸âƒ£ Build prompt for LLM:
   Context: [Top-5 chunks]
   History: [Previous Q&A]
   Question: "à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™à¸¡à¸µà¸­à¸°à¹„à¸£à¸šà¹‰à¸²à¸‡?"

5ï¸âƒ£ LLM generates answer with citations
```

#### **Step 4: à¹„à¸”à¹‰à¸„à¸³à¸•à¸­à¸š**

```json
{
  "success": true,
  "kb_name": "gun_law",
  "session_id": "user123_gun_20251125",
  "answer": "à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™à¸¡à¸µà¸”à¸±à¸‡à¸™à¸µà¹‰:\n\n1. **à¹€à¸•à¸£à¸µà¸¢à¸¡à¹€à¸­à¸à¸ªà¸²à¸£:**\n   - à¸ªà¸³à¹€à¸™à¸²à¸šà¸±à¸•à¸£à¸›à¸£à¸°à¸Šà¸²à¸Šà¸™\n   - à¸ªà¸³à¹€à¸™à¸²à¸—à¸°à¹€à¸šà¸µà¸¢à¸™à¸šà¹‰à¸²à¸™\n   - à¸£à¸¹à¸›à¸–à¹ˆà¸²à¸¢à¸‚à¸™à¸²à¸” 1 à¸™à¸´à¹‰à¸§ à¸ˆà¸³à¸™à¸§à¸™ 2 à¹ƒà¸š\n\n2. **à¸¢à¸·à¹ˆà¸™à¸„à¸³à¸‚à¸­:**\n   - à¸¢à¸·à¹ˆà¸™à¸„à¸³à¸‚à¸­à¸—à¸µà¹ˆà¸ªà¸–à¸²à¸™à¸µà¸•à¸³à¸£à¸§à¸ˆà¹ƒà¸™à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸­à¸¢à¸¹à¹ˆà¸­à¸²à¸¨à¸±à¸¢\n   - à¸Šà¸³à¸£à¸°à¸„à¹ˆà¸²à¸˜à¸£à¸£à¸¡à¹€à¸™à¸µà¸¢à¸¡ 1,000 à¸šà¸²à¸—\n\n3. **à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´:**\n   - à¸•à¸³à¸£à¸§à¸ˆà¸ˆà¸°à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸­à¸²à¸Šà¸à¸²à¸à¸£à¸£à¸¡\n   - à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œà¹€à¸à¸·à¹ˆà¸­à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸„à¸§à¸²à¸¡à¸ˆà¸³à¹€à¸›à¹‡à¸™\n\n4. **à¸£à¸±à¸šà¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•:**\n   - à¸£à¸­à¸œà¸¥à¸à¸´à¸ˆà¸²à¸£à¸“à¸² 30-60 à¸§à¸±à¸™\n   - à¸«à¸²à¸à¸­à¸™à¸¸à¸¡à¸±à¸•à¸´ à¸¡à¸²à¸£à¸±à¸šà¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸—à¸µà¹ˆà¸ªà¸–à¸²à¸™à¸µà¸•à¸³à¸£à¸§à¸ˆ\n\n**à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸:** à¸œà¸¹à¹‰à¸‚à¸­à¸•à¹‰à¸­à¸‡à¸¡à¸µà¸­à¸²à¸¢à¸¸à¹„à¸¡à¹ˆà¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² 20 à¸›à¸µà¸šà¸£à¸´à¸šà¸¹à¸£à¸“à¹Œ à¹à¸¥à¸°à¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸­à¸²à¸Šà¸à¸²à¸à¸£à¸£à¸¡",
  "sources": [
    {
      "content": "à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸¢à¸·à¹ˆà¸™à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™\n1. à¹€à¸•à¸£à¸µà¸¢à¸¡à¹€à¸­à¸à¸ªà¸²à¸£à¸›à¸£à¸°à¸à¸­à¸š...",
      "metadata": {
        "kb_name": "gun_law",
        "filename": "gun_license_handbook.pdf",
        "page_number": 12,
        "doc_type": "Official Document",
        "category": "Legal"
      }
    }
  ]
}
```

#### **Step 5: Agent à¹à¸ªà¸”à¸‡à¸œà¸¥**
```
Agent: "à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™à¸¡à¸µà¸”à¸±à¸‡à¸™à¸µà¹‰à¸„à¹ˆà¸°:

1. **à¹€à¸•à¸£à¸µà¸¢à¸¡à¹€à¸­à¸à¸ªà¸²à¸£:**
   - à¸ªà¸³à¹€à¸™à¸²à¸šà¸±à¸•à¸£à¸›à¸£à¸°à¸Šà¸²à¸Šà¸™
   - à¸ªà¸³à¹€à¸™à¸²à¸—à¸°à¹€à¸šà¸µà¸¢à¸™à¸šà¹‰à¸²à¸™
   - à¸£à¸¹à¸›à¸–à¹ˆà¸²à¸¢à¸‚à¸™à¸²à¸” 1 à¸™à¸´à¹‰à¸§ à¸ˆà¸³à¸™à¸§à¸™ 2 à¹ƒà¸š

2. **à¸¢à¸·à¹ˆà¸™à¸„à¸³à¸‚à¸­:**
   - à¸¢à¸·à¹ˆà¸™à¸„à¸³à¸‚à¸­à¸—à¸µà¹ˆà¸ªà¸–à¸²à¸™à¸µà¸•à¸³à¸£à¸§à¸ˆà¹ƒà¸™à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸­à¸¢à¸¹à¹ˆà¸­à¸²à¸¨à¸±à¸¢
   - à¸Šà¸³à¸£à¸°à¸„à¹ˆà¸²à¸˜à¸£à¸£à¸¡à¹€à¸™à¸µà¸¢à¸¡ 1,000 à¸šà¸²à¸—

3. **à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´:**
   - à¸•à¸³à¸£à¸§à¸ˆà¸ˆà¸°à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸­à¸²à¸Šà¸à¸²à¸à¸£à¸£à¸¡
   - à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œà¹€à¸à¸·à¹ˆà¸­à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸„à¸§à¸²à¸¡à¸ˆà¸³à¹€à¸›à¹‡à¸™

4. **à¸£à¸±à¸šà¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•:**
   - à¸£à¸­à¸œà¸¥à¸à¸´à¸ˆà¸²à¸£à¸“à¸² 30-60 à¸§à¸±à¸™
   - à¸«à¸²à¸à¸­à¸™à¸¸à¸¡à¸±à¸•à¸´ à¸¡à¸²à¸£à¸±à¸šà¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸—à¸µà¹ˆà¸ªà¸–à¸²à¸™à¸µà¸•à¸³à¸£à¸§à¸ˆ

**à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸:** à¸œà¸¹à¹‰à¸‚à¸­à¸•à¹‰à¸­à¸‡à¸¡à¸µà¸­à¸²à¸¢à¸¸à¹„à¸¡à¹ˆà¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² 20 à¸›à¸µà¸šà¸£à¸´à¸šà¸¹à¸£à¸“à¹Œ

ğŸ“š **à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡à¸ˆà¸²à¸:**
- gun_license_handbook.pdf (à¸«à¸™à¹‰à¸² 12)
"
```

---

### **à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆ 2: à¹„à¸¡à¹ˆà¸£à¸°à¸šà¸¸ KB (chat_global) - Semantic Router ğŸŒ**

**Scenario:** User à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¸§à¹ˆà¸²à¸•à¹‰à¸­à¸‡à¸–à¸²à¸¡ KB à¹„à¸«à¸™

#### **Step 1: à¸–à¸²à¸¡à¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸›**
```
User: "à¸šà¸­à¸à¸«à¸™à¹ˆà¸­à¸¢à¸§à¹ˆà¸²à¸ˆà¸°à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™à¸¢à¸±à¸‡à¹„à¸‡?"
```

#### **Step 2: Agent à¹ƒà¸Šà¹‰ Semantic Router**

**Agent à¹„à¸¡à¹ˆà¸£à¸¹à¹‰ KB â†’ à¹€à¸£à¸µà¸¢à¸ `chat_global`** (à¸£à¸°à¸šà¸šà¸«à¸²à¹ƒà¸«à¹‰à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´)

```json
{
  "query": "à¸šà¸­à¸à¸«à¸™à¹ˆà¸­à¸¢à¸§à¹ˆà¸²à¸ˆà¸°à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™à¸¢à¸±à¸‡à¹„à¸‡?",
  "session_id": "user123_auto_20251125",
  "top_k": 5
}
```

#### **Step 3: Semantic Routing (Behind the scenes)**

```
ğŸŒ Auto-routing query: 'à¸šà¸­à¸à¸«à¸™à¹ˆà¸­à¸¢à¸§à¹ˆà¸²à¸ˆà¸°à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™à¸¢à¸±à¸‡à¹„à¸‡?'

1ï¸âƒ£ Embed query â†’ [0.21, -0.43, 0.87, ...] (1024-dim)

2ï¸âƒ£ Search master_router_index (à¸„à¹‰à¸™à¸«à¸² KB à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡)
   
   Available KBs:
   - kb_gun_law: "[Official] à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™ - Legal"
   - kb_medical: "[Medical] Patient Care Procedures"
   - kb_hr_policy: "[HR] Employee Handbook"
   
   Similarity scores:
   âœ… kb_gun_law: 0.89 (highest!)
   âŒ kb_medical: 0.23
   âŒ kb_hr_policy: 0.15

3ï¸âƒ£ Check threshold: 0.89 > 0.4 âœ…

ğŸ¯ Router found: gun_law (score: 0.890)
   Description: [Official] à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™ - Legal

âœ… Routed to: gun_law (confidence: 0.890)

4ï¸âƒ£ Now call chat_with_collection(kb_name="gun_law", ...)
   [Same as à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆ 1 from here...]
```

#### **Step 4: à¹„à¸”à¹‰à¸„à¸³à¸•à¸­à¸šà¸à¸£à¹‰à¸­à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Routing**

```json
{
  "success": true,
  "kb_name": "gun_law",
  "session_id": "user123_auto_20251125",
  "answer": "[Same detailed answer as above]",
  "sources": [...],
  "routed_to": "gun_law",
  "routing_confidence": 0.89,
  "routing_method": "semantic_similarity"
}
```

#### **Step 5: Agent à¹à¸ªà¸”à¸‡à¸œà¸¥**
```
Agent: "ğŸ¯ à¸£à¸°à¸šà¸šà¸•à¸£à¸§à¸ˆà¸à¸šà¸§à¹ˆà¸²à¸„à¸³à¸–à¸²à¸¡à¸™à¸µà¹‰à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸š 'gun_law' (à¸„à¸§à¸²à¸¡à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆ: 89%)

[Same answer as above...]

ğŸ’¡ **Tip:** à¸„à¸³à¸–à¸²à¸¡à¸–à¸±à¸”à¹„à¸›à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸š gun law à¸ªà¸²à¸¡à¸²à¸£à¸–à¸–à¸²à¸¡à¸•à¹ˆà¸­à¹„à¸”à¹‰à¹€à¸¥à¸¢à¸„à¹ˆà¸° 
à¸£à¸°à¸šà¸šà¸ˆà¸°à¸ˆà¸³à¸šà¸—à¸ªà¸™à¸—à¸™à¸²à¹„à¸§à¹‰à¹ƒà¸«à¹‰"
```

---

### **ğŸ”„ à¸•à¹ˆà¸­à¸šà¸—à¸ªà¸™à¸—à¸™à¸² (Conversation History)**

#### **à¸„à¸³à¸–à¸²à¸¡à¸—à¸µà¹ˆ 2 (Same Session):**
```
User: "à¹à¸¥à¹‰à¸§à¸„à¹ˆà¸²à¸˜à¸£à¸£à¸¡à¹€à¸™à¸µà¸¢à¸¡à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆ?"
```

**System:**
```
ğŸ“ Using session: user123_gun_20251125
ğŸ“š Retrieved conversation history:
   Q1: "à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™à¸¡à¸µà¸­à¸°à¹„à¸£à¸šà¹‰à¸²à¸‡?"
   A1: "à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™à¸¡à¸µà¸”à¸±à¸‡à¸™à¸µà¹‰: 1. à¹€à¸•à¸£à¸µà¸¢à¸¡à¹€à¸­à¸à¸ªà¸²à¸£..."

ğŸ” Context-aware search:
   - Query: "à¹à¸¥à¹‰à¸§à¸„à¹ˆà¸²à¸˜à¸£à¸£à¸¡à¹€à¸™à¸µà¸¢à¸¡à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆ?"
   - + Previous context: "à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™"
   â†’ Understands: à¸–à¸²à¸¡à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸„à¹ˆà¸²à¸˜à¸£à¸£à¸¡à¹€à¸™à¸µà¸¢à¸¡ "à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™"

âœ… Answer: "à¸„à¹ˆà¸²à¸˜à¸£à¸£à¸¡à¹€à¸™à¸µà¸¢à¸¡à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™à¸„à¸·à¸­ 1,000 à¸šà¸²à¸— 
   (à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸à¸¥à¹ˆà¸²à¸§à¹„à¸§à¹‰à¹ƒà¸™à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 2 à¸‚à¸­à¸‡à¸„à¸³à¸•à¸­à¸šà¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²)"
```

---

### **ğŸ¨ à¸„à¸§à¸²à¸¡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ chat_with_kb vs chat_global:**

| Feature | chat_with_kb | chat_global |
|---------|--------------|-------------|
| **KB Selection** | à¸•à¹‰à¸­à¸‡à¸£à¸°à¸šà¸¸ kb_name | âœ… Auto-route |
| **Speed** | à¹€à¸£à¹‡à¸§à¸à¸§à¹ˆà¸² (~50ms) | à¸Šà¹‰à¸²à¸à¸§à¹ˆà¸²à¸™à¸´à¸” (~110ms) |
| **Use When** | à¸£à¸¹à¹‰ KB à¸Šà¸±à¸”à¹€à¸ˆà¸™ | à¹„à¸¡à¹ˆà¸£à¸¹à¹‰ KB à¸«à¸£à¸·à¸­à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹ƒà¸«à¹‰à¸£à¸°à¸šà¸šà¸«à¸² |
| **Accuracy** | 100% (à¸–à¸¹à¸ KB) | 85-95% (depend on router) |
| **Best For** | API, specific queries | AI Agent, general questions |

---

## ğŸ“š MCP Tools Reference

### **1. create_collection**
à¸ªà¸£à¹‰à¸²à¸‡ Knowledge Base à¹ƒà¸«à¸¡à¹ˆ (à¹à¸•à¹ˆà¹à¸™à¸°à¸™à¸³à¹ƒà¸«à¹‰à¸‚à¹‰à¸²à¸¡ â†’ à¹ƒà¸Šà¹‰ auto_create à¹ƒà¸™ upload)

```json
{
  "name": "create_collection",
  "arguments": {
    "kb_name": "medical_records",
    "description": "Patient medical records and history"
  }
}
```

---

### **2. upload_document_to_kb** â­
à¸­à¸±à¸à¹‚à¸«à¸¥à¸”à¹€à¸­à¸à¸ªà¸²à¸£à¹„à¸›à¸¢à¸±à¸‡ KB (auto-create à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µ)

```json
{
  "name": "upload_document_to_kb",
  "arguments": {
    "kb_name": "medical_records",
    "file_content": "JVBERi0xLjQK...",  // base64
    "filename": "patient_001.pdf",
    "content_type": "application/pdf",
    "auto_create": true  // à¸ªà¸£à¹‰à¸²à¸‡ KB à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µ
  }
}
```

**AI à¸ˆà¸°à¸—à¸³à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´:**
- à¸ªà¸à¸±à¸” metadata (doc_type, category, title)
- à¸ªà¸£à¹‰à¸²à¸‡ description
- à¸ªà¸£à¹‰à¸²à¸‡ KB (à¸–à¹‰à¸² auto_create=true)
- Update semantic router index

---

### **3. chat_with_kb** â­
à¸„à¸¸à¸¢à¸à¸±à¸š KB à¸—à¸µà¹ˆà¸£à¸°à¸šà¸¸ (à¸¡à¸µ conversation history)

```json
{
  "name": "chat_with_kb",
  "arguments": {
    "kb_name": "medical_records",
    "query": "What's the patient's blood type?",
    "session_id": "doctor123_patient001",
    "top_k": 5
  }
}
```

**Returns:**
- `answer`: à¸„à¸³à¸•à¸­à¸šà¸ˆà¸²à¸ LLM
- `sources`: à¹€à¸­à¸à¸ªà¸²à¸£à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡ (à¸à¸£à¹‰à¸­à¸¡ page number)
- `session_id`: à¸ªà¸³à¸«à¸£à¸±à¸šà¸•à¹ˆà¸­à¸šà¸—à¸ªà¸™à¸—à¸™à¸²

---

### **4. chat_global** ğŸŒ â­
à¸„à¸¸à¸¢à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸£à¸°à¸šà¸¸ KB (à¸£à¸°à¸šà¸šà¸«à¸²à¹ƒà¸«à¹‰à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´)

```json
{
  "name": "chat_global",
  "arguments": {
    "query": "How do I apply for a gun license?",
    "session_id": "user123_auto",
    "top_k": 5
  }
}
```

**Returns:**
- [Same as chat_with_kb] +
- `routed_to`: KB à¸—à¸µà¹ˆà¸–à¸¹à¸à¹€à¸¥à¸·à¸­à¸
- `routing_confidence`: à¸„à¸°à¹à¸™à¸™à¸„à¸§à¸²à¸¡à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆ (0-1)
- `routing_method`: "semantic_similarity"

**à¸–à¹‰à¸² routing failed:**
```json
{
  "success": false,
  "message": "I don't know which knowledge base to use",
  "available_kbs": ["gun_law", "medical", "hr_policy"]
}
```

---

### **5. list_collections**
à¸”à¸¹à¸£à¸²à¸¢à¸à¸²à¸£ KB à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”

```json
{
  "name": "list_collections",
  "arguments": {}
}
```

**Returns:**
```json
{
  "success": true,
  "collections": [
    {
      "kb_name": "gun_law",
      "collection_name": "kb_gun_law",
      "description": "[Official] à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™ - Legal",
      "vector_count": 892,
      "created_at": "2025-11-25T10:30:00"
    }
  ],
  "total": 1
}
```

---

### **6. get_collection_info**
à¸”à¸¹à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸‚à¸­à¸‡ KB

```json
{
  "name": "get_collection_info",
  "arguments": {
    "kb_name": "gun_law"
  }
}
```

**Returns:**
- Vector count
- Collection size
- Metadata (description, created_at)

---

### **7. clear_chat_history**
à¸¥à¸šà¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸à¸²à¸£à¸ªà¸™à¸—à¸™à¸²

```json
{
  "name": "clear_chat_history",
  "arguments": {
    "kb_name": "gun_law",
    "session_id": "user123_gun_20251125"
  }
}
```

---

### **8. delete_collection**
à¸¥à¸š KB à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” (à¸£à¸°à¸§à¸±à¸‡: à¸¥à¸šà¹€à¸­à¸à¸ªà¸²à¸£à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”!)

```json
{
  "name": "delete_collection",
  "arguments": {
    "kb_name": "gun_law"
  }
}
```

---

## ğŸš€ Advanced Features

### **1. Semantic Router (Master Index)**

à¸£à¸°à¸šà¸š Semantic Router à¹ƒà¸Šà¹‰ **Master Index** (`master_router_index`) à¹€à¸à¸·à¹ˆà¸­à¸ˆà¸±à¸šà¸„à¸¹à¹ˆ query à¸à¸±à¸š KB

**How it works:**
1. à¹à¸•à¹ˆà¸¥à¸° KB à¸¡à¸µ **description** (AI-generated)
2. Description à¸–à¸¹à¸ embed â†’ à¹€à¸à¹‡à¸šà¹ƒà¸™ master_router_index
3. à¹€à¸¡à¸·à¹ˆà¸­ user à¸–à¸²à¸¡à¸„à¸³à¸–à¸²à¸¡ â†’ embed query â†’ à¸„à¹‰à¸™à¸«à¸² KB à¸—à¸µà¹ˆ description à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸—à¸µà¹ˆà¸ªà¸¸à¸”
4. à¸–à¹‰à¸² score > 0.4 â†’ route à¹„à¸› KB à¸™à¸±à¹‰à¸™

**Example:**
```
Query: "How to renew my gun license?"
â†’ Embed: [0.21, -0.43, 0.87, ...]
â†’ Search master_router_index
â†’ Best match: kb_gun_law (score: 0.89)
â†’ Route to kb_gun_law
```

**Adjusting threshold:**
```python
# In app/multi_kb_rag.py
ROUTER_SIMILARITY_THRESHOLD = 0.4  # Default

# More lenient (more matches):
ROUTER_SIMILARITY_THRESHOLD = 0.3

# More strict (fewer matches):
ROUTER_SIMILARITY_THRESHOLD = 0.5
```

---

### **2. AI Metadata Extraction**

à¹€à¸¡à¸·à¹ˆà¸­à¸­à¸±à¸à¹‚à¸«à¸¥à¸”à¹€à¸­à¸à¸ªà¸²à¸£ AI à¸ˆà¸°à¸­à¹ˆà¸²à¸™ **à¸«à¸™à¹‰à¸²à¹à¸£à¸** à¹à¸¥à¸°à¸ªà¸à¸±à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥:

```json
{
  "doc_type": "Official Document | Technical Manual | Research Paper | ...",
  "category": "Legal | Medical | Technical | HR | ...",
  "status": "Published | Draft | Archived",
  "title": "à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™"
}
```

**Smart Description Generation:**
```
Format: "[{doc_type}] {title} - Category: {category} ({status})"

Example: "[Official Document] à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¸à¸²à¸£à¸‚à¸­à¹ƒà¸šà¸­à¸™à¸¸à¸à¸²à¸•à¸›à¸·à¸™ - Category: Legal (Published)"
```

This description is crucial for Semantic Router!

---

### **3. Conversation Memory Management**

à¸£à¸°à¸šà¸šà¹€à¸à¹‡à¸š conversation history à¹à¸¢à¸à¸•à¸²à¸¡:
- **Collection:** à¹à¸•à¹ˆà¸¥à¸° KB à¸¡à¸µ memory à¹à¸¢à¸à¸à¸±à¸™
- **Session ID:** à¹à¸•à¹ˆà¸¥à¸° session à¸¡à¸µ memory à¹à¸¢à¸à¸à¸±à¸™

**Structure:**
```python
chat_histories[collection_name][session_id] = ConversationBufferMemory
```

**Best Practices for session_id:**
```python
# Good: Descriptive and consistent
session_id = f"{user_id}_{topic}_{date}"
# Examples:
- "user123_gun_20251125"
- "doctor456_patient001"
- "agent789_legal_20251125"

# Bad: Too generic or random
session_id = "session_123"  # âŒ Not descriptive
session_id = str(uuid.uuid4())  # âŒ New session every time
```

---

### **4. Multi-File Upload to Same KB**

```python
# Upload multiple documents to same KB
files = ["doc1.pdf", "doc2.pdf", "doc3.pdf"]

for file in files:
    upload_document_to_kb(
        kb_name="legal_docs",  # Same KB
        file_content=encode_base64(file),
        filename=file,
        auto_create=True  # Only creates KB once
    )
```

**Result:**
- Single KB: `kb_legal_docs`
- Multiple documents indexed together
- Single description (from first upload)

---

### **5. Performance Tips**

#### **Optimize Vector Search:**
```python
# Adjust top_k based on document size
chat_with_kb(
    kb_name="large_kb",
    query="...",
    top_k=3  # Smaller = faster, less context
    # top_k=10  # Larger = slower, more context
)
```

#### **Batch Uploads:**
```python
# Instead of:
for doc in docs:
    upload_document(...)  # âŒ Slow

# Do:
# Upload all docs first, then chat
upload_document(doc1)
upload_document(doc2)
upload_document(doc3)
chat_with_kb(...)  # All docs indexed
```

#### **Cache Collections List:**
```python
# Cache list_collections() result (changes infrequently)
collections = list_collections()  # Call once
# Use cached result for multiple operations
```

---

## ğŸ“¡ API Examples

### **cURL Examples:**

#### **Initialize Connection:**
```bash
curl -X POST http://localhost:8000/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "id": 1,
    "method": "initialize",
    "params": {
      "protocolVersion": "2024-11-05",
      "capabilities": {},
      "clientInfo": {"name": "my-client", "version": "1.0"}
    }
  }'
```

#### **Upload Document:**
```bash
curl -X POST http://localhost:8000/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "id": 2,
    "method": "tools/call",
    "params": {
      "name": "upload_document_to_kb",
      "arguments": {
        "kb_name": "my_kb",
        "file_content": "'$(base64 -i document.pdf)'",
        "filename": "document.pdf",
        "content_type": "application/pdf",
        "auto_create": true
      }
    }
  }'
```

#### **Chat Global:**
```bash
curl -X POST http://localhost:8000/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "id": 3,
    "method": "tools/call",
    "params": {
      "name": "chat_global",
      "arguments": {
        "query": "What are the requirements?",
        "session_id": "user123_session1",
        "top_k": 5
      }
    }
  }'
```

---

## ğŸ› Troubleshooting

### **Problem: "Collection does not exist"**

**Cause:** KB à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸–à¸¹à¸à¸ªà¸£à¹‰à¸²à¸‡

**Solution:**
```python
# Option 1: Use auto_create
upload_document_to_kb(..., auto_create=True)  # âœ…

# Option 2: Create manually first
create_collection(kb_name="my_kb")
upload_document_to_kb(...)
```

---

### **Problem: "Router index is empty"**

**Cause:** à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µ KB à¹ƒà¸”à¹† à¹ƒà¸™à¸£à¸°à¸šà¸š (à¹ƒà¸Šà¹‰ chat_global à¹„à¸¡à¹ˆà¹„à¸”à¹‰)

**Solution:**
```python
# Upload at least one document first
upload_document_to_kb(...)

# Then chat_global will work
chat_global(query="...")
```

---

### **Problem: "Low routing confidence"**

**Cause:** Query à¹„à¸¡à¹ˆ match à¸à¸±à¸š KB descriptions

**Solution:**
```python
# 1. Lower threshold (app/multi_kb_rag.py)
ROUTER_SIMILARITY_THRESHOLD = 0.3  # More lenient

# 2. Or use specific KB
chat_with_kb(kb_name="my_kb", ...)  # Skip routing

# 3. Upload more documents â†’ better descriptions
```

---

### **Problem: "Context loss in conversation"**

**Cause:** session_id à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸—à¸¸à¸à¸„à¸£à¸±à¹‰à¸‡

**Solution:**
```python
# âŒ Bad: New session every time
session_id = str(uuid.uuid4())

# âœ… Good: Consistent session ID
session_id = "user123_topic_20251125"  # Reuse for same conversation
```

---

### **Problem: "Server slow to start"**

**Cause:** Load embeddings model at startup

**Solution:**
```bash
# Pre-download model (one-time)
python3 -c "
from langchain_huggingface import HuggingFaceEmbeddings
HuggingFaceEmbeddings(model_name='BAAI/bge-m3')
"

# Next startup will be faster
```

---

## ğŸ“Š Monitoring & Logs

### **Log Files:**
```
logs/server.log  # All requests, errors, debug info
```

### **Log Levels:**
- **Console:** INFO (clean output)
- **File:** DEBUG (detailed)

### **View Logs:**
```bash
# Real-time logs
tail -f logs/server.log

# Last 50 lines
tail -50 logs/server.log

# Search for errors
grep ERROR logs/server.log

# Search for specific KB
grep "gun_law" logs/server.log
```

### **Log Rotation:**
- Max size: 10 MB
- Backups: 5 files
- Total: 50 MB max

---

## ğŸ¤ Integration with AI Agents

### **Dify Integration:**

1. **Add MCP Server in Dify:**
   ```
   Tools â†’ MCP Servers â†’ Add Server
   URL: http://localhost:8000/mcp  (or ngrok URL)
   Name: multi-kb-rag-server
   ```

2. **Create Agent:**
   ```
   Model: GPT-4
   Tools: Select all 8 tools
   Instructions: "You are a document assistant..."
   ```

3. **Test:**
   ```
   User: "Upload this PDF and answer questions about it"
   Agent: [Uses upload_document_to_kb + chat_with_kb]
   ```

### **Custom Integration:**

```python
import requests

class RAGClient:
    def __init__(self, base_url="http://localhost:8000"):
        self.base_url = base_url
        self.msg_id = 0
    
    def call_tool(self, tool_name, arguments):
        self.msg_id += 1
        response = requests.post(
            f"{self.base_url}/mcp",
            json={
                "jsonrpc": "2.0",
                "id": self.msg_id,
                "method": "tools/call",
                "params": {
                    "name": tool_name,
                    "arguments": arguments
                }
            }
        )
        return response.json()
    
    def upload(self, kb_name, file_path):
        import base64
        with open(file_path, 'rb') as f:
            content = base64.b64encode(f.read()).decode()
        
        return self.call_tool("upload_document_to_kb", {
            "kb_name": kb_name,
            "file_content": content,
            "filename": file_path.split('/')[-1],
            "content_type": "application/pdf",
            "auto_create": True
        })
    
    def chat(self, query, session_id="default", kb_name=None):
        if kb_name:
            return self.call_tool("chat_with_kb", {
                "kb_name": kb_name,
                "query": query,
                "session_id": session_id
            })
        else:
            return self.call_tool("chat_global", {
                "query": query,
                "session_id": session_id
            })

# Usage
client = RAGClient()
client.upload("my_kb", "document.pdf")
result = client.chat("What's in the document?")
print(result)
```

---

## ğŸ“š Additional Resources

- **Semantic Router Implementation:** [SEMANTIC_ROUTER_IMPLEMENTATION.md](SEMANTIC_ROUTER_IMPLEMENTATION.md)
- **Performance Optimization:** [OPTIMIZATION_GUIDE.md](OPTIMIZATION_GUIDE.md)
- **Logging Guide:** [LOGGING_GUIDE.md](LOGGING_GUIDE.md)

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) file

---

## ğŸ™‹ Support

**Issues:** https://github.com/YourRepo/rag-mcp-server/issues  
**Discord:** [Join our community](#)  
**Email:** support@example.com

---

**Built with â¤ï¸ using FastAPI, LangChain, Qdrant, and HuggingFace**
